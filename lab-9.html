<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Lab 9</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 52px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h2 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h3 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h4 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h5 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h6 {
  padding-top: 57px;
  margin-top: -57px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="overview.html">Overview</a>
</li>
<li>
  <a href="js-introduction.html">JS Intro</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lab 4
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lab-4.html">Lab 4a</a>
    </li>
    <li>
      <a href="lab-4b.html">Lab 4b</a>
    </li>
  </ul>
</li>
<li>
  <a href="lab-5.html">Lab 5</a>
</li>
<li>
  <a href="lab-6.html">Lab 6</a>
</li>
<li>
  <a href="lab-7.html">Lab 7</a>
</li>
<li>
  <a href="lab-8.html">Lab 8</a>
</li>
<li>
  <a href="lab-9.html">Lab 9</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Lab 9</h1>

</div>


<p><br></p>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In the previous two labs you used non-parametric models <span class="math inline">\(f\)</span> that relate predictor variables <span class="math inline">\(X\)</span> to a response variable <span class="math inline">\(Y\)</span>. There was in the context of prediction tasks where given <span class="math inline">\(x\)</span> inputs a trained model <span class="math inline">\(\hat{f}\)</span> will predict a response <span class="math inline">\(\hat{y}\)</span>.</p>
<p><span class="math display">\[\hat{y}=\hat{f}(x)\]</span> Non-parametric models do not make any prior assumptions about the functional form of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (i.e. there is no requirement that <span class="math inline">\(f\)</span> is linear, quadratic, or another form of model). For example, when you trained a classification tree model in lab 7 you did not make prior assumptions about the functional form of the relationship between <span class="math inline">\(X\)</span> (spectral reflectance values) and <span class="math inline">\(Y\)</span> (land cover categories). During the process of training a non-parametric model the data informs the estimation of <span class="math inline">\(f\)</span> and its model of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p>Parametric models are another group of statistical models that relate values of <span class="math inline">\(X\)</span> predictors to an outcome <span class="math inline">\(Y\)</span>; if you have estimated a linear regression model before you have used a parametric model. Parametric models consist of a finite number of parameters to estimate. To use the example of a linear regression model; <span class="math inline">\(f\)</span> consists of <span class="math inline">\(p + 1\)</span> parameters - <em>slope</em> coefficients <span class="math inline">\(\beta_{1}, \beta_{2},...,\beta_{p}\)</span> for each of the <span class="math inline">\(X_{1}, X_{2},...,X_{p}\)</span> predictors and an <em>intercept</em> parameter <span class="math inline">\(\beta_{0}\)</span>.</p>
<p>The process of training a parametric model involves estimating parameter values that minimise a loss function. The loss function is a measure of the difference between the observed response variable <span class="math inline">\(y\)</span> and the predicted response <span class="math inline">\(\hat{y}\)</span>. In linear regression, the estimated parameter values minimise the least squares criterion. This involves estimating values for <span class="math inline">\(\beta_{0}, \beta_{1},...,\beta_{p}\)</span> that minimise the residual sum of squares (RSS). Mathematically, this involves finding the values of <span class="math inline">\(\beta_{0}, \beta_{1},...,\beta_{p}\)</span> that result in lowest sum of squared differences between observed <span class="math inline">\(y\)</span> and <span class="math inline">\(\hat{y}\)</span> for all <span class="math inline">\(i\)</span> data training data points. For a simple linear regression with one predictor <span class="math inline">\(X_{1}\)</span>:</p>
<p><span class="math display">\[  RSS\left(\hat\beta_0, \hat\beta_1\right) = \sum_{i=1}^n\left[y_i - \left(\hat\beta_0 + \hat\beta_1 x_i\right)\right]^2 \]</span></p>
<p>Graphically, this can be conceptualised as identifying parameters that define a line fitted through the data points that minimises the vertical distance between the line and all training data points. For a linear regression model with one predictor this can be visualised as:</p>
<p><br></p>
<div class="figure" style="text-align: center">
<img src="img/linear-regression-1-predictor-james-et-al-2013.png" alt="Least squares fit for a linear regression model with one predictor variable (source: James et al. (2013))." width="80%" />
<p class="caption">
Least squares fit for a linear regression model with one predictor variable (source: James et al. (2013)).
</p>
</div>
<p><br></p>
<p>If you have more than one predictor variable, the fitted model with parameters that minimise the difference between observed <span class="math inline">\(y\)</span> and predicted <span class="math inline">\(\hat{y}\)</span> is illustrated below.</p>
<p><br></p>
<div class="figure" style="text-align: center">
<img src="img/multi-linear-regression-james-et-al-2013.png" alt="Least squares fit for a multiple linear regression model with more than one predictor variable (source: James et al. (2013))." width="80%" />
<p class="caption">
Least squares fit for a multiple linear regression model with more than one predictor variable (source: James et al. (2013)).
</p>
</div>
<p><br></p>
<p>If there is a relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> which is captured by <span class="math inline">\(f\)</span> such that:</p>
<p><span class="math display">\[Y = f(X) + \epsilon\]</span></p>
<p>and you assume <span class="math inline">\(f\)</span> is a linear regression model with a slope and intercept parameter and one predictor variable <span class="math inline">\(X_{1}\)</span> you can rewrite the above equation as:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X_{1} + \epsilon\]</span></p>
<p>You don’t know the true values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> but you can estimate them from your training data:</p>
<p><span class="math display">\[\hat{y} = \hat\beta_0 + \hat\beta_1 x + \hat\epsilon\]</span> where:</p>
<ul>
<li><span class="math inline">\(\hat\beta_0\)</span> is the estimated intercept parameter (the value at which the line of best fit intersects with the Y-axis). <span class="math inline">\(\hat\beta_0\)</span> represents the mean value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X = 0\)</span>.</li>
<li><span class="math inline">\(\hat\beta_1\)</span> is the estimated slope coefficient; the slope coefficient <span class="math inline">\(\hat\beta_1\)</span> represents the change in <span class="math inline">\(Y\)</span> for a one unit change in <span class="math inline">\(X\)</span>.</li>
<li><span class="math inline">\(\hat\epsilon\)</span> is the residual which is an estimate of the model’s mean zero random error term <span class="math inline">\(\epsilon\)</span>; <span class="math inline">\(\hat\epsilon\)</span> is computed as the difference between observed <span class="math inline">\(y\)</span> and predicted <span class="math inline">\(\hat{y}\)</span>.</li>
</ul>
<p>If your predictor variable <span class="math inline">\(X\)</span> is temporal (i.e. years, months) then the line of best fit and the slope coefficient <span class="math inline">\(\beta\)</span> represent trends in <span class="math inline">\(Y\)</span> over time. The sign on the slope coefficient indicates the direction of the trend (positive - increasing over time - or negative - decreasing over time). The value of the slope coefficient indicates the rate of change in <span class="math inline">\(Y\)</span> over time.</p>
<p>This lab will introduce tools for training parametric models in Google Earth Engine. You will use these models to detect trends in urban vegetation and land surface temperature (LST) across a study area in urban Perth. You will also learn techniques for inference (i.e. identifying if trends you observe are statistically significant), assessing model fit, and evaluating the strengths and weaknesses of a given parametric model for a particular application.</p>
<div id="data" class="section level3">
<h3>Data</h3>
<p>You will use 30 years of annual greenest pixel Landsat data to estimate temporal trends in urban vegetation. This data is derived from Landsat 5, Landsat 7, and Landsat 8 top of atmosphere (TOA) reflectance data. The records for the data in Google Earth Engine data catalog are <a href="https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_ANNUAL_GREENEST_TOA" target="_blank">here</a>; also see <a href="https://www.sciencedirect.com/science/article/abs/pii/S0034425709000169" target="_blank">Chander et al. (2009)</a>.</p>
<p>For the LST data you will use the MODIS MYD11A2 product (<a href="https://www.sciencedirect.com/science/article/pii/S003442571300285X?casa_token=iYMc72sMa4sAAAAA:z41SIlkBRjhKbvyygsUML9LHM_omiYLlna6yJT_DAF1NTfg8YlmWwefAyQjYe13dGdOEf2qHjg" target="_blank">Wan (2014)</a>). This data has a 1 km spatial resolution with an 8 day temporal resolution with observations from the year 2000. The reference for this data on the Google Earth Engine data catalog is <a href="https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MYD11A2#bands" target="_blank">here</a>.</p>
</div>
<div id="setup" class="section level3">
<h3>Setup</h3>
<p><br></p>
<pre class="js"><code>/*
Lab 9
Author: Test
Date: XX-XX-XXXX

*/
</code></pre>
<p><br></p>
</div>
<div id="data-import---landsat-ndvi" class="section level3">
<h3>Data Import - Landsat NDVI</h3>
<p>First, to visualise change in urban land cover between 1990 and 2019 import the following two Landsat TOA <code>Image</code>s. <code>l1990</code> is a Landsat 5 multispectral composite <code>Image</code> from 1990 and <code>l2019</code> is a Landsat 8 multispectral <code>Image</code> from 2019.</p>
<p>Visualise the two <code>Image</code>s as RGB composites on the map display; switch between the two <code>Image</code>s and you should be able to see the effects of urban development since 1990.</p>
<p><br></p>
<pre class="js"><code>// Study area
var bBox = 
    /* color: #0b4a8b */
    /* shown: false */
    /* displayProperties: [
      {
        &quot;type&quot;: &quot;rectangle&quot;
      }
    ] */
    ee.Geometry.Polygon(
        [[[115.71190972343935, -31.726395823091245],
          [115.71190972343935, -31.935245757597972],
          [116.07308526054872, -31.935245757597972],
          [116.07308526054872, -31.726395823091245]]], null, false);
Map.centerObject(bBox, 11);     
Map.addLayer(bBox, {}, &#39;study area&#39;);

// 1990 Landsat TOA Greenest
var l1990 = ee.Image(&#39;users/jmad1v07/gee-labs/landsat5-1990-toa&#39;);

// 2019 Landsat TOA Greenest
var l2019 = ee.Image(&#39;users/jmad1v07/gee-labs/landsat8-2019-toa&#39;);

// Visualise 1990 and 2019 Landsat RGB Images
// RGB visualisation parameters
var trueColorVis = {
  min: 0,
  max: 0.4,
  gamma: 1.2,
};

// 1990
Map.addLayer(l1990, trueColorVis, &#39;L5 1990&#39;);

// 2019
Map.addLayer(l2019, trueColorVis, &#39;L8 2019&#39;);
</code></pre>
<p><br></p>
<p><br></p>
<div class="figure" style="text-align: center">
<img src="img/l5-1990-toa-rgb.png" alt="Landsat 5 TOA RGB composite `Image` - 1990." width="80%" />
<p class="caption">
Landsat 5 TOA RGB composite <code>Image</code> - 1990.
</p>
</div>
<p><br></p>
<div class="figure" style="text-align: center">
<img src="img/l8-2019-toa-rgb.png" alt="Landsat 8 TOA RGB composite `Image` - 2019." width="80%" />
<p class="caption">
Landsat 8 TOA RGB composite <code>Image</code> - 2019.
</p>
</div>
<p><br></p>
<p>Next, import an <code>ImageCollection</code> storing <code>Images</code> that contain the greenest NDVI value for each pixel-year combination from 1990 to 2020 derived from Landsat 5, Landsat 7, and Landsat 8 data. Inspect this data’s properties in the <em>console</em>; there should be 31 <code>Image</code>s.</p>
<p><br></p>
<pre class="js"><code>//1990 - 2020 Landsat TOA Greenest Image Collection
var landsatNDVI = ee.ImageCollection(&#39;users/jmad1v07/gee-labs/landsat-toa-perth&#39;);
print(landsatNDVI);
</code></pre>
<p><br></p>
<p>Before estimating linear regression models to identify temporal trends in the data you can visually inspect trends in NDVI at each pixel. The following code allows you to click on any pixel in the map display and a chart displaying NDVI values for each year and a line of best fit will be rendered on the <em>console</em>.</p>
<p><br></p>
<pre class="js"><code>// Visually explore trends in NDVI
function curve(coords){
  var geometry = ee.Geometry.Point(coords.lon, coords.lat);
  var chart = ui.Chart.image.seriesByRegion(landsatNDVI, geometry, ee.Reducer.mean(), &#39;ndvi&#39;, 30, &#39;system:time_start&#39;)
    .setChartType(&#39;ScatterChart&#39;)
    .setOptions({
      title: &#39;NDVI&#39;,
      lineWidth: 1,
      pointSize: 3,
      trendlines: {0: {
        color: &#39;#000000&#39;
      }},
      hAxis: {
        title: &#39;Date&#39;
      },
      vAxis: {
        title: &#39;NDVI&#39;
      },
      series: {
      0: {
        color: &#39;#238b45&#39;},
        }
    });

  print(chart);
}
Map.add(ui.Label(&#39;Click in study area to make an NDVI chart...&#39;));
Map.onClick(curve);
</code></pre>
<p><br></p>
<center>
<iframe src="https://player.vimeo.com/video/462315277" width="640" height="319" frameborder="0" allow="autoplay; fullscreen" allowfullscreen>
</iframe>
<p>
Generate charts visualising NDVI trends over time.
</p>
</center>
<p><br></p>
</div>
<div id="data-import---modis-lst" class="section level3">
<h3>Data Import - MODIS LST</h3>
<p>First, you need to import the MODIS MYD11A2 product <code>ImageCollection</code> which stores 8 day temporal resolution LST data. You will need to filter this data for Perth’s summer months (January and February) and for pixels that intersect with the study region <code>bBox</code>. You do this using the <code>ee.Filter.calendarRange()</code> and <code>filterBounds()</code> functions.</p>
<p>Next, you need to reduce this <code>ImageCollection</code> so that it stores an <code>Image</code> for each year where each pixel’s value is the median LST for all observations within a year. You also give each <code>Image</code> a band named <code>year</code> which is an <code>Image</code> where each pixel’s value is the year. This <code>year</code> band will become the predictor variable when training regression models to identify trends in LST over time. You will notice that you multiply LST values by 0.02 - LST values in the MYD11A2 product need to be rescaled by 0.02 to recover values in Kelvin.</p>
<p><br></p>
<pre class="js"><code>// MODIS LST
var modisSummerLST = ee.ImageCollection(&quot;MODIS/006/MYD11A2&quot;)
  .filter(ee.Filter.calendarRange(1, 2, &#39;month&#39;)) 
  .filterBounds(bBox);
print(modisSummerLST);

// Compute annual average MODIS LST
// year list
var years = ee.List.sequence(2003, 2020, 1);
print(years);

// Jan and Feb median Image composite
modisSummerLST = ee.ImageCollection.fromImages(
  years.map(function(year) {
  var modisSummerMedian = modisSummerLST.filter(ee.Filter.calendarRange(year, year, &#39;year&#39;))
      .select(&#39;LST_Day_1km&#39;)
      .median()
      .multiply(0.02);
  return ee.Image.constant(year).float()
          .addBands(modisSummerMedian).rename([&#39;year&#39;, &#39;modis_lst&#39;])
          .clip(bBox);
  }));
print(&#39;MODIS Summer LST:&#39;, modisSummerLST);
</code></pre>
<br>
<hr>
<p><br></p>
</div>
</div>
<div id="training-linear-regression-models" class="section level2">
<h2>Training Linear Regression Models</h2>
<p>There are numerous functions that can be called in Google Earth Engine to estimate linear regression models. Here, you will use the reducer <code>linearFit()</code> method. This method can be called on an <code>ImageCollection</code> where each <code>Image</code> has two bands; the first band is the predictor variable and the second band is the response variable. If you inspect either <code>landsatNDVI</code> or <code>modisSummerLST</code> you should see that the first band is named <code>year</code>. This is the predictor variable as you are seeking to identify temporal trends in either NDVI or LST over time.</p>
<p>A call to <code>linearFit()</code> returns an <code>Image</code> with two bands named <code>scale</code> and <code>offset</code>. The <code>scale</code> band is an <code>Image</code> of slope coefficients for each pixel indicating the sign (positive / negative) and rate of change in NDVI or LST. The <code>offset</code> band is an <code>Image</code> of intercept values for each pixel.</p>
<p>You can map the <code>scale</code> band to visualise temporal trends in NDVI or LST on the map display. There is a guide to linear regression models in Google Earth Engine <a href="https://developers.google.com/earth-engine/guides/reducers_regression" target="_blank">here</a>.</p>
<p><br></p>
<pre class="js"><code>// Linear regression - trend analysis
// NDVI trends
var lRegNDVI = landsatNDVI.reduce(ee.Reducer.linearFit());
print(&#39;NDVI regression&#39;, lRegNDVI);
Map.addLayer(lRegNDVI.select(&#39;scale&#39;), {min: -0.025, max: 0.025, palette:[&#39;#d73027&#39;,&#39;#fc8d59&#39;,&#39;#fee08b&#39;,&#39;#ffffbf&#39;,&#39;#d9ef8b&#39;,&#39;#91cf60&#39;,&#39;#1a9850&#39;]}, &#39;NDVI Trend&#39;);

// LST trends
var lRegLST = modisSummerLST.reduce(ee.Reducer.linearFit());
print(&#39;LST regression&#39;, lRegLST);
Map.addLayer(lRegLST.select(&#39;scale&#39;), {min: -0.2, max: 0.2, palette:[&#39;#2166ac&#39;, &#39;#67a9cf&#39;, &#39;#d1e5f0&#39;, &#39;#f7f7f7&#39;, &#39;#fddbc7&#39;, &#39;#ef8a62&#39;, &#39;#b2182b&#39;]}, &#39;LST Trend&#39;);
</code></pre>
<p><br></p>
<p>Look at areas on the map where there have been increasing or decreasing trends in NDVI. Do they correspond to observable changes in land cover that you could see in the two RGB composite <code>Image</code>s for 1990 and 2019?</p>
<p><br></p>
<div class="figure" style="text-align: center">
<img src="img/ndvi-trends.png" alt="NDVI trends." width="80%" />
<p class="caption">
NDVI trends.
</p>
</div>
<p><br></p>
<details>
<summary><b><em>There are only 18 years of MODIS LST data. What is a risk of using a relatively short time-series for trend detection?</em></b></summary>
<p>
<br> The trend you estimate is sensitive to outliers or noise; for example, an anomalously high LST value late in the time-series could pull your trend upwards. Also, there might long-run cycles in your time-series that could be conflated with a trend when a short time-series is used.
</p>
</details>
<p><br></p>
<div class="figure" style="text-align: center">
<img src="img/lst-trends.png" alt="LST trends." width="80%" />
<p class="caption">
LST trends.
</p>
</div>
<p><br></p>
<hr>
<p><br></p>
</div>
<div id="model-fit" class="section level2">
<h2>Model Fit</h2>
<p>Generate charts of NDVI values over time for areas where your linear regression model has estimated increasing or decreasing trends (use the click function to print charts in the <em>console</em>).</p>
<details>
<summary><b><em>How good a job do you think a linear regression model is doing at identifying and representing temporal trends in NDVI?</em></b></summary>
<p>
<p><br> There are some locations where the trend in NDVI is clearly not linear. In such locations a linear model might not be appropriate for trend detection. You could identify trends using more flexible models that can account for non-linear relationships between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (e.g. using a quadratic model with <span class="math inline">\(X^{2}\)</span> as a predictor) or use algorithms that can detect abrupt changes in time-series (e.g. <a href="https://emapr.github.io/LT-GEE/" target="_blank">LandTrendr</a>).</p>
<div class="figure" style="text-align: center">
<img src="img/abrupt-change-ndvi.png" alt="Abrupt - non-linear change in NDVI" width="70%" />
<p class="caption">
Abrupt - non-linear change in NDVI
</p>
</div>
</p>
</details>
<p><br></p>
<p>Beyond visually inspecting how well the model (a linear model here) fits the data, you can compute statistics that quantify model fit.</p>
<div id="residual-standard-error" class="section level3">
<h3>Residual Standard Error</h3>
<p>The residual standard error (RSE; sometimes called standard error of the regression) is an estimate the standard deviation of the error term <span class="math inline">\(\epsilon\)</span>. It is computed as:</p>
<p><span class="math display">\[ RSE = \sqrt{\frac{1}{n-p-1} \sum^n_{i=1}(y_i - \hat y_i)^2} \]</span> The RSE is a measure of, on average, how much a prediction <span class="math inline">\(\hat{y}_i\)</span> deviates from the true value <span class="math inline">\(y_{i}\)</span> for a model <span class="math inline">\(\hat{f}(X)\)</span>. If the RSE is small then it indicates the model fits the data well; conversely, if the RSE is large then it indicates the model does not fit the data well.</p>
<p>You can compute the RSE for each location where you estimated a trend in NDVI. Areas with higher RSE values are mapped in deeper red shades; compare these locations on the map to charts visualising trends in NDVI at that location in the <em>console</em>. At locations with higher RSE values you should observe greater spread in observed NDVI values around the estimated trend line.</p>
<p><br></p>
<pre class="js"><code>// RSE
var n = lNDVI.size();
print(&#39;number of observations:&#39;, n);

var rse = lNDVI.map(function(image) {
  var yHat = image.select(&#39;year&#39;).multiply(lRegNDVI.select(&#39;scale&#39;)).add(lRegNDVI.select(&#39;offset&#39;));
  var residualSquared = image.select(&#39;ndvi&#39;).subtract(yHat).pow(2);
  return residualSquared;
}).sum()
  .multiply(ee.Number(1).divide(n.subtract(2)))
  .sqrt();
  
Map.addLayer(rse, {min: 0, max: 0.2, palette:[&#39;#fee5d9&#39;,&#39;#fcae91&#39;,&#39;#fb6a4a&#39;,&#39;#de2d26&#39;,&#39;#a50f15&#39;]}, &#39;RSE&#39;);
</code></pre>
<p><br></p>
</div>
<div id="r2-statistic" class="section level3">
<h3><span class="math inline">\(R^{2}\)</span> statistic</h3>
<p>The RSE statistic provides a measure of the absolute fit of the model. However, as it is in units of <span class="math inline">\(Y\)</span> it is not always clear what constitutes a good fit. The <span class="math inline">\(R^{2}\)</span> is another statistic used to measure the fit of the model; it represents a value between 0 and 1 which indicates the proportion of the variance in <span class="math inline">\(Y\)</span> explained by <span class="math inline">\(f(X)\)</span>. It can be interpreted independent of the units of <span class="math inline">\(Y\)</span>.</p>
<p>The <span class="math inline">\(R^{2}\)</span> is computed as:</p>
<p><span class="math display">\[ R^{2} = 1-\frac{RSS}{TSS} \]</span></p>
<p>where RSS is the residual sum of squares:</p>
<p><span class="math display">\[ RSS = \sum^n_{i=1}(y_i - \hat y_i)^2 \]</span> and TSS is the total sum of squares:</p>
<p><span class="math display">\[ TSS = \sum^n_{i=1}(y_i - \bar y)^2 \]</span> The TSS is a measure of the variance in <span class="math inline">\(Y\)</span>; it is the sum of the squared deviations of observations <span class="math inline">\(y_{i}\)</span> from the sample mean <span class="math inline">\(\bar y\)</span>. The RSS is the amount of variation in <span class="math inline">\(Y\)</span> not explained by the trained model <span class="math inline">\(\hat{f}(X)\)</span>. Thus, the formula for the <span class="math inline">\(R^{2}\)</span> indicates the amount of variance in <span class="math inline">\(Y\)</span> (TSS) that is explained by the trained model <span class="math inline">\(\hat{f}(X)\)</span>. The higher the value of the <span class="math inline">\(R^{2}\)</span> the more variation in <span class="math inline">\(Y\)</span> is explained by the model and the better it fits the data.</p>
<p>You can estimate the <span class="math inline">\(R^{2}\)</span> for each trend in NDVI that you estimated as:</p>
<p><br></p>
<pre class="js"><code>// R Squared
var rss = lNDVI.map(function(image) {
  var yHat = image.select(&#39;year&#39;).multiply(lRegNDVI.select(&#39;scale&#39;)).add(lRegNDVI.select(&#39;offset&#39;));
  var residualSquared = image.select(&#39;ndvi&#39;).subtract(yHat).pow(2);
  return residualSquared;
}).sum();

var meanY = lNDVI.select(&#39;ndvi&#39;).mean();

var tss = lNDVI.map(function(image) {
  var devSquared = image.select(&#39;ndvi&#39;).subtract(meanY).pow(2);
  return devSquared;
}).sum();

var rSquared = ee.Image.constant(1).subtract(rss.divide(tss));
Map.addLayer(rSquared, {min: 0, max: 1, palette:[&#39;#f2f0f7&#39;,&#39;#cbc9e2&#39;,&#39;#9e9ac8&#39;,&#39;#756bb1&#39;,&#39;#54278f&#39;]}, &#39;R Squared&#39;);
</code></pre>
<p><br></p>
<p>Areas in darker purple shades have a higher <span class="math inline">\(R^{2}\)</span> value. Compare these locations to charts visualising the trend in NDVI for those pixels in the <em>console</em>. There should be less scatter in observed NDVI values around the trend line.</p>
<hr>
<p><br></p>
</div>
</div>
<div id="confidence-intervals" class="section level2">
<h2>Confidence Intervals</h2>
<p>The values that you estimated for the parameters indicate the size and sign of the effect of the predictor on the response; here, the sign and rate of change in trends of <span class="math inline">\(Y\)</span> over time. The RSE and <span class="math inline">\(R^{2}\)</span> measure how well the model you trained fits the data. However, these statistics do not indicate whether the trends you have observed are statistically significant. A trend is statistically significant if the probability of observing that trend is very small when the null hypothesis of no trend is true. A hypothesis test can be performed to determine if an estimated parameter value (i.e. the trend over time) is statistically significant.</p>
<p>In the context of testing for statistically significant trends, you pose two hypotheses:</p>
<p><span class="math display">\[H_{0}: \beta_{1} = 0\]</span></p>
<p><span class="math inline">\(H_{0}\)</span> is the null hypothesis where the trend is equal to zero. The alternative hypothesis <span class="math inline">\(H_{1}\)</span> is that the trend is not equal to zero.</p>
<p><span class="math display">\[H_{1}: \beta_{1} \neq 0\]</span></p>
<p>You perform a hypothesis test to test for statistical significance; based upon your data is there evidence “beyond reasonable doubt” that the null hypothesis of no trend is false? When performing a hypothesis test you need to decide a <em>significance level</em> <span class="math inline">\(\alpha\)</span>; this is the <b>Type I error</b> which is the probability of falsely rejecting the null hypothesis when it is true that you are willing to accept. Commonly a 5% significance level is used (<span class="math inline">\(\alpha = 0.05\)</span>).</p>
<p>You can test for statistical significance by computing confidence intervals for a parameter estimate. A confidence interval is a range which has a <span class="math inline">\(1 - \alpha\)</span> probability of containing the true value of the parameter you are estimating. If the confidence interval surrounding <span class="math inline">\(\hat\beta_1\)</span> (your trend estimate) contains 0 then you cannot reject the null hypothesis <span class="math inline">\(H_{0}: \beta_{1} = 0\)</span> at a significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>You can compute the sampling standard deviation (standard error) of your estimated parameter value. This gives an indication of the variability (or uncertainty) in your estimate of the trend. You can compute the standard error of your trend estimate as:</p>
<p><span class="math display">\[\hat\sigma_{\beta_1}=\sqrt\frac{\hat\sigma_{\epsilon}^{2}}{\sum^n_{i=1}(x_i - \bar x)^2}\]</span> where the the denominator is the variance of <span class="math inline">\(X_{1}\)</span> and the numerator <span class="math inline">\(\hat\sigma_{\epsilon}^{2}\)</span> is the variance of the residuals:</p>
<p><span class="math display">\[ \hat\sigma_{\epsilon}^{2}=\frac{1}{n-p-1} \sum^n_{i=1}(y_i - \hat y_i)^2\]</span> The smaller the value of <span class="math inline">\(\hat\sigma_{\epsilon}^{2}\)</span> the smaller the standard error <span class="math inline">\(\hat\sigma_{\beta_1}\)</span> of your trend estimate. This makes sense, if the the variance in the residuals is small it indicates your model is fitting the data well. If the variance of <span class="math inline">\(X_{1}\)</span> is large, the standard error <span class="math inline">\(\hat\sigma_{\beta_1}\)</span> of your trend estimate <span class="math inline">\(\beta_1\)</span> will be smaller; if values of your predictor <span class="math inline">\(x\)</span> are more spread out you have more leverage to estimate a slope.</p>
<p>You can compute the standard error <span class="math inline">\(\hat\sigma_{\epsilon}^{2}\)</span> for each of your estimates pixel-wise NDVI trends as:</p>
<p><br></p>
<pre class="js"><code>// Confidence Intervals
// variance of residuals
var varE = lNDVI.map(function(image) {
  var yHat = image.select(&#39;year&#39;).multiply(lRegNDVI.select(&#39;scale&#39;)).add(lRegNDVI.select(&#39;offset&#39;));
  var residualSquared = image.select(&#39;ndvi&#39;).subtract(yHat).pow(2);
  return residualSquared;
}).sum()
  .multiply(ee.Number(1).divide(n.subtract(2)));

//variance of X
var meanX = lNDVI.select(&#39;year&#39;).mean();

var varX = lNDVI.map(function(image) {
  var devSquared = image.select(&#39;year&#39;).subtract(meanX).pow(2);
  return devSquared;
}).sum();

// standard error of trend estimate
var seB = varE.divide(varX).sqrt();
</code></pre>
<p><br></p>
<p>The standard error of your estimated trend <span class="math inline">\(\hat\sigma_{\beta_1}\)</span> is a measure of the uncertainty in your estimate (if you took repeat samples how much your estimate would change from sample to sample). Confidence intervals indicate how close the true trend is likely to be to your estimated trend. You can compute confidence intervals using the standard error of your estimated trend <span class="math inline">\(\hat\sigma_{\beta_1}\)</span>. You can approximate the 95 % confidence interval as:</p>
<p><span class="math display">\[[\hat\beta_{k} \pm 2 \cdot \hat\sigma_{\beta_1}]\]</span> Execute the following code to compute the 95 % confidence intervals for each of your trends.</p>
<p><br></p>
<pre class="js"><code>// compute confidence intervals
var ciLow = lRegNDVI.select(&#39;scale&#39;).subtract(seB.multiply(2));
var ciHigh = lRegNDVI.select(&#39;scale&#39;).add(seB.multiply(2));
</code></pre>
<p>As stated above, the confidence intervals are the range that will contain the unknown true value of the trend with a 95 % probability. If your confidence intervals contain 0 then you cannot reject the null hypothesis that the trend you estimated is equal to 0.</p>
<p>To identify statistically significant trends (i.e. locations where you can reject the null hypothesis of the trend being equal to 0) find all locations where the upper and lower confidence intervals were greater than or less than 0.</p>
<p><br></p>
<pre class="js"><code>// locations where confidence intervals do not include 0
var statSigPositive = ciLow.gt(0).and(ciHigh.gt(0));
var statSigNegative = ciLow.lt(0).and(ciHigh.lt(0));

// locations with statistically significant trends
var statSig = statSigPositive.add(statSigNegative).gt(0);
</code></pre>
<p><br></p>
<p>Finally, you want to mask out all trends in NDVI that are not statistically significant. This will allow you to map only statistically significant trends in NDVI at the <span class="math inline">\(\alpha = 0.05\)</span> significance level.</p>
<pre class="js"><code>// mask not significant trends
var sigTrends = lRegNDVI.select(&#39;scale&#39;).updateMask(statSig);
Map.addLayer(sigTrends, {min: -0.025, max: 0.025, palette:[&#39;#d73027&#39;,&#39;#fc8d59&#39;,&#39;#fee08b&#39;,&#39;#ffffbf&#39;,&#39;#d9ef8b&#39;,&#39;#91cf60&#39;,&#39;#1a9850&#39;]}, &#39;Stat. Significant NDVI Trend&#39;);
</code></pre>
<p><br></p>
<p>Turn off all other layers and set the basemap to satellite. You should see a map like the below figure showing only the locations of statistically significant trends in NDVI.</p>
<p><br></p>
<div class="figure" style="text-align: center">
<img src="img/sig-trends-ndvi.png" alt="Statistically significant trends in NDVI 1990-2020." width="80%" />
<p class="caption">
Statistically significant trends in NDVI 1990-2020.
</p>
</div>
<p><br></p>
<details>
<summary><b><em>You have just performed a large number of significance tests (one in each pixel). What problem occurs due to this approach of multiple hypothesis testing?</em></b></summary>
<p>
<br> You are performing multiple hypothesis tests where each test has a 0.05 (5 %) probability of a false positive (rejecting the null hypothesis when it is true). By chance you will expect some significant results when performing multiple hypothesis tests; this number of false positives could be large when performing a large number of hypothesis tests such as in each pixel of a satellite <code>Image</code>. One approach to addressing this issue is to use the <a href="https://en.wikipedia.org/wiki/Bonferroni_correction" target="_blank">Bonferroni correction</a> where your significance level becomes <span class="math inline">\(0.05 / m\)</span> if your original significance level was <span class="math inline">\(\alpha = 0.05\)</span> and you perfom <span class="math inline">\(m\)</span> hypothesis tests.
</p>
</details>
<p><br></p>
<p><br></p>
<hr>
<p><br></p>
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
<footer>
<p>
Advanced GIS and Remote Sensing
</p>
</footer>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
